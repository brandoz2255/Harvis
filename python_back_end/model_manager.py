"""
Model Management System for GPU Memory Optimization
Handles loading/unloading of TTS, Whisper, and Qwen2VL models
"""

import os
import torch
import logging
import time
import gc
from typing import Optional

logger = logging.getLogger(__name__)

# Import model classes
try:
    import whisper
except ImportError:
    # Try alternative whisper import
    try:
        import openai_whisper as whisper
    except ImportError:
        logger.error("No whisper package found. Please install with: pip install openai-whisper")
        whisper = None
from chatterbox.tts import ChatterboxTTS
from tts_engine_manager import (
    TTSMode,
    set_mode,
    get_mode,
    generate_speech as tts_generate_speech,
    generate_podcast_segment,
    get_engine_status,
    unload_all_engines,
    load_chatterbox,
    unload_chatterbox,
)

# ‚îÄ‚îÄ‚îÄ MONKEYPATCH: Fix broken perth dependency in Chatterbox ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    import perth
    if not hasattr(perth, 'PerthImplicitWatermarker'):
        logger.warning("‚ö†Ô∏è Patching missing 'PerthImplicitWatermarker' in perth module")
        class MockWatermarker:
            def __init__(self): pass
            def __call__(self, *args, **kwargs): return None
            def embed(self, audio, sample_rate): return audio
            def apply_watermark(self, audio, sample_rate): return audio # Correct method name
        perth.PerthImplicitWatermarker = MockWatermarker
except ImportError:
    pass
except Exception as e:
    logger.warning(f"Failed to patch perth: {e}")

logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ Global Model Variables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
tts_model = None
whisper_model = None
_cuda_is_broken = False  # Flag to disable CUDA if architecture mismatch detected

# ‚îÄ‚îÄ‚îÄ VRAM Management ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def get_vram_threshold():
    if not torch.cuda.is_available():
        return float('inf')

    total_mem = torch.cuda.get_device_properties(0).total_memory
    return max(int(total_mem * 0.8), 10 * 1024**3)

THRESHOLD_BYTES = get_vram_threshold()
logger.info(f"VRAM threshold set to {THRESHOLD_BYTES/1024**3:.1f} GiB")

def wait_for_vram(threshold=THRESHOLD_BYTES, interval=0.5):
    if not torch.cuda.is_available():
        return
    used = torch.cuda.memory_allocated()
    while used > threshold:
        logger.info(f"VRAM {used/1024**3:.1f} GiB > {threshold/1024**3:.1f} GiB. Waiting‚Ä¶")
        time.sleep(interval)
        used = torch.cuda.memory_allocated()
    torch.cuda.empty_cache()
    logger.info("VRAM is now below threshold. Proceeding with TTS.")

# ‚îÄ‚îÄ‚îÄ Memory Monitoring ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def log_gpu_memory(stage: str):
    """Log current GPU memory usage"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        free = total - allocated
        logger.info(f"üîç GPU Memory {stage}: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved, {free:.2f}GB free")

def get_gpu_memory_stats():
    """Get detailed GPU memory statistics"""
    if not torch.cuda.is_available():
        return {
            "available": False,
            "message": "CUDA not available"
        }

    allocated = torch.cuda.memory_allocated()
    reserved = torch.cuda.memory_reserved()
    total = torch.cuda.get_device_properties(0).total_memory
    free = total - allocated

    stats = {
        "available": True,
        "allocated_gb": allocated / 1024**3,
        "reserved_gb": reserved / 1024**3,
        "total_gb": total / 1024**3,
        "free_gb": free / 1024**3,
        "allocated_bytes": allocated,
        "reserved_bytes": reserved,
        "total_bytes": total,
        "free_bytes": free,
        "usage_percent": (allocated / total) * 100,
        "device_name": torch.cuda.get_device_name(0),
        "device_count": torch.cuda.device_count()
    }

    return stats

def check_memory_pressure():
    """Check if system is under memory pressure and suggest actions"""
    stats = get_gpu_memory_stats()

    if not stats["available"]:
        return {
            "pressure_level": "unknown",
            "message": "CUDA not available",
            "recommendations": []
        }

    usage_percent = stats["usage_percent"]
    recommendations = []

    if usage_percent > 90:
        pressure_level = "critical"
        recommendations = [
            "Unload all models immediately",
            "Enable aggressive auto-unloading",
            "Consider using smaller models",
            "Check for memory leaks"
        ]
    elif usage_percent > 75:
        pressure_level = "high"
        recommendations = [
            "Unload unused models",
            "Enable auto-unloading for all models",
            "Monitor model usage patterns"
        ]
    elif usage_percent > 50:
        pressure_level = "moderate"
        recommendations = [
            "Consider enabling auto-unloading",
            "Monitor memory usage trends"
        ]
    else:
        pressure_level = "low"
        recommendations = ["Memory usage is healthy"]

    return {
        "pressure_level": pressure_level,
        "usage_percent": usage_percent,
        "free_gb": stats["free_gb"],
        "allocated_gb": stats["allocated_gb"],
        "total_gb": stats["total_gb"],
        "recommendations": recommendations,
        "auto_cleanup_suggested": pressure_level in ["high", "critical"]
    }

def auto_cleanup_if_needed(threshold_percent=75):
    """Automatically cleanup models if memory usage exceeds threshold"""
    pressure = check_memory_pressure()

    if not pressure.get("auto_cleanup_suggested", False):
        return False

    logger.warning(f"üö® Memory pressure detected: {pressure['pressure_level']} ({pressure['usage_percent']:.1f}% used)")
    logger.info("üßπ Performing automatic model cleanup...")

    # Unload models in order of priority
    cleanup_actions = []

    global tts_model, whisper_model

    if tts_model is not None:
        unload_tts_model()
        cleanup_actions.append("TTS model unloaded")

    if whisper_model is not None:
        unload_whisper_model()
        cleanup_actions.append("Whisper model unloaded")

    # Also unload Qwen model if available
    try:
        from vison_models.llm_connector import unload_qwen_model
        unload_qwen_model()
        cleanup_actions.append("Qwen2VL model unloaded")
    except Exception as e:
        logger.warning(f"Could not unload Qwen model: {e}")

    # Force aggressive cleanup
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        gc.collect()
        torch.cuda.empty_cache()
        cleanup_actions.append("GPU cache cleared")

    logger.info(f"‚úÖ Cleanup completed: {', '.join(cleanup_actions)}")

    # Check memory again
    new_pressure = check_memory_pressure()
    logger.info(f"üìä Memory after cleanup: {new_pressure['usage_percent']:.1f}% used, {new_pressure['free_gb']:.2f}GB free")

    return True

# ‚îÄ‚îÄ‚îÄ Model Loading Functions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def load_tts_model(force_cpu=False):
    """Load TTS model with memory management"""
    global tts_model, _cuda_is_broken
    
    if _cuda_is_broken:
        logger.warning("‚ö†Ô∏è CUDA marked as broken, forcing CPU load for TTS")
        force_cpu = True
        
    tts_device = "cuda" if torch.cuda.is_available() and not force_cpu else "cpu"

    if tts_model is None:
        try:
            logger.info(f"üîä Loading TTS model on device: {tts_device}")

            # LOG CACHE CONFIGURATION
            hf_cache = os.environ.get('TRANSFORMERS_CACHE', os.environ.get('HF_HOME', '~/.cache/huggingface'))
            hf_cache_expanded = os.path.expanduser(hf_cache)
            logger.info(f"üìÅ HuggingFace cache directory: {hf_cache_expanded}")

            if os.path.exists(hf_cache_expanded):
                try:
                    cache_contents = os.listdir(hf_cache_expanded)
                    logger.info(f"üì¶ HF cache contains {len(cache_contents)} items: {cache_contents[:5]}")
                    # Check for model directories
                    model_dirs = [d for d in cache_contents if d.startswith('models--')]
                    if model_dirs:
                        logger.info(f"‚úÖ Found {len(model_dirs)} cached models: {model_dirs}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not list cache contents: {e}")
            else:
                logger.warning(f"‚ö†Ô∏è HF cache directory does not exist: {hf_cache_expanded}")
            # Add timeout for CUDA loading to prevent hanging
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("TTS model loading timed out")
            
            if tts_device == "cuda":
                # COMPREHENSIVE CUDA DIAGNOSTICS
                logger.info("üîß Starting comprehensive CUDA diagnostics for TTS...")

                if torch.cuda.is_available():
                    try:
                        # Test basic CUDA operations
                        logger.info(f"üìä CUDA Device Count: {torch.cuda.device_count()}")
                        logger.info(f"üìä Current CUDA Device: {torch.cuda.current_device()}")
                        logger.info(f"üìä CUDA Device Name: {torch.cuda.get_device_name()}")

                        # Test CUDA memory operations
                        logger.info("üß™ Testing basic CUDA memory operations...")
                        test_tensor = torch.ones(100, device='cuda')
                        logger.info(f"‚úÖ Basic CUDA tensor creation successful: {test_tensor.device}")
                        del test_tensor

                        # Check for active CUDA contexts
                        try:
                            import pynvml
                            pynvml.nvmlInit()
                            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                            info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                            logger.info(f"üìä GPU Memory via NVML: {info.used/1024**3:.2f}GB used / {info.total/1024**3:.2f}GB total")
                        except ImportError:
                            logger.warning("‚ö†Ô∏è pynvml not available, skipping NVML memory check")
                        except Exception as nvml_e:
                            logger.warning(f"‚ö†Ô∏è NVML check failed: {nvml_e}")

                    except Exception as cuda_test_e:
                        logger.error(f"‚ùå Basic CUDA test failed: {cuda_test_e}")
                        raise RuntimeError(f"CUDA is broken: {cuda_test_e}")

                # CRITICAL: Force GPU memory cleanup before TTS loading
                logger.info("üîß Performing aggressive GPU memory cleanup before TTS...")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    # Force garbage collection
                    import gc
                    gc.collect()
                    torch.cuda.empty_cache()
                    # Wait for cleanup to complete
                    import time
                    time.sleep(1.0)
                    log_gpu_memory("before TTS load after cleanup")

                # Set 180 second timeout for CUDA loading (TTS takes ~90-120s to load from cache)
                signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(180)
                try:
                    logger.info("üöÄ Attempting ChatterboxTTS.from_pretrained(device='cuda')...")

                    # Additional safety: Test ChatterboxTTS import first
                    try:
                        from chatterbox.tts import ChatterboxTTS
                        logger.info("‚úÖ ChatterboxTTS import successful")
                    except Exception as import_e:
                        logger.error(f"‚ùå ChatterboxTTS import failed: {import_e}")
                        raise ImportError(f"ChatterboxTTS unavailable: {import_e}")

                    # Attempt TTS model loading with additional error context
                    # Enable transformers logging to see what's happening
                    import transformers
                    transformers.logging.set_verbosity_info()

                    logger.info(f"üîÑ Loading ChatterboxTTS with cache_dir={hf_cache_expanded}")
                    logger.info("üì• This may use cached models or download if cache is missing...")

                    tts_model = ChatterboxTTS.from_pretrained(device=tts_device)
                    signal.alarm(0)  # Cancel timeout
                    logger.info("‚úÖ TTS model loaded successfully on CUDA")

                    # Reset logging verbosity
                    transformers.logging.set_verbosity_warning()

                except TimeoutError:
                    signal.alarm(0)  # Cancel timeout
                    logger.warning("‚è∞ TTS CUDA loading timed out, falling back to CPU...")
                    tts_device = "cpu"
                    try:
                        tts_model = ChatterboxTTS.from_pretrained(device="cpu")
                        logger.info("‚úÖ TTS model loaded successfully on CPU (timeout fallback)")
                    except Exception as cpu_fallback_e:
                        logger.error(f"‚ùå CPU fallback also failed: {cpu_fallback_e}")
                        raise RuntimeError("TTS loading failed on both CUDA (timeout) and CPU") from cpu_fallback_e

                except Exception as cuda_load_e:
                    signal.alarm(0)  # Cancel timeout
                    logger.error(f"‚ùå TTS CUDA loading failed: {cuda_load_e}")
                    logger.error(f"‚ùå Exception type: {type(cuda_load_e).__name__}")
                    logger.error(f"‚ùå Exception args: {cuda_load_e.args}")

                    # Try to get more detailed error information
                    import traceback
                    logger.error(f"‚ùå Full traceback: {traceback.format_exc()}")

                    # Attempt CPU fallback with detailed logging
                    logger.warning("üîÑ Attempting CPU fallback after CUDA failure...")
                    try:
                        tts_device = "cpu"
                        tts_model = ChatterboxTTS.from_pretrained(device="cpu")
                        logger.info("‚úÖ TTS model loaded successfully on CPU (CUDA failure fallback)")
                    except Exception as cpu_fallback_e:
                        logger.error(f"‚ùå CPU fallback also failed: {cpu_fallback_e}")
                        # DON'T RAISE - return None and handle gracefully
                        logger.error("‚ùå TTS completely unavailable - continuing without TTS")
                        return None
            else:
                tts_model = ChatterboxTTS.from_pretrained(device=tts_device)
        except Exception as e:
            if "cuda" in str(e).lower():
                logger.warning(f"‚ö†Ô∏è CUDA load failed: {e}. Falling back to CPU...")
                try:
                    tts_model = ChatterboxTTS.from_pretrained(device="cpu")
                    logger.info("‚úÖ Successfully loaded TTS model on CPU")
                except Exception as e2:
                    logger.error(f"‚ùå Failed to load TTS model on CPU: {e2}")
                    raise RuntimeError("TTS model loading failed on both CUDA and CPU.") from e2
            else:
                logger.error(f"‚ùå TTS model loading error: {e}")
                raise
    return tts_model

def load_whisper_model():
    """Load Whisper model with memory management"""
    global whisper_model
    if whisper_model is None:
        if whisper is None:
            logger.error("‚ùå Whisper not available - install with: pip install openai-whisper")
            return None

        try:
            logger.info("üîÑ Loading Whisper model with surgical GPU fixes")

            # LOG WHISPER CACHE CONFIGURATION
            whisper_cache = os.environ.get('WHISPER_CACHE', os.path.expanduser('~/.cache/whisper'))
            logger.info(f"üìÅ Whisper cache directory: {whisper_cache}")

            if os.path.exists(whisper_cache):
                try:
                    cache_files = os.listdir(whisper_cache)
                    logger.info(f"üì¶ Whisper cache contains: {cache_files}")
                    pt_files = [f for f in cache_files if f.endswith('.pt')]
                    if pt_files:
                        logger.info(f"‚úÖ Found {len(pt_files)} cached Whisper models: {pt_files}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not list Whisper cache: {e}")
            else:
                logger.warning(f"‚ö†Ô∏è Whisper cache directory does not exist: {whisper_cache}")
            
            # SURGICAL FIX 1: Force CUDA init early to prevent hanging
            import signal
            def cuda_timeout_handler(signum, frame):
                raise TimeoutError("CUDA operation timed out")
            
            if torch.cuda.is_available():
                logger.info("üîß Pre-warming CUDA to prevent init hangs...")
                signal.signal(signal.SIGALRM, cuda_timeout_handler)
                signal.alarm(15)  # 15 second timeout for CUDA init
                try:
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    _ = torch.cuda.current_device()
                    logger.info("‚úÖ CUDA pre-warm successful")
                    signal.alarm(0)
                except Exception as cuda_e:
                    signal.alarm(0)
                    logger.error(f"‚ùå CUDA pre-warm failed: {cuda_e}")
                    raise RuntimeError(f"CUDA initialization failed: {cuda_e}")
            
            # SURGICAL FIX 2: Check if model already exists in cache (avoids download entirely)
            import os
            cache_dir = os.path.expanduser("~/.cache/whisper")
            logger.info(f"üìÅ Checking Whisper cache directory: {cache_dir}")
            
            if os.path.exists(cache_dir):
                files = os.listdir(cache_dir)
                logger.info(f"üìÅ Whisper cache contents: {files}")
                # Look for any .pt files (model files)
                model_files = [f for f in files if f.endswith('.pt')]
                if model_files:
                    logger.info(f"‚úÖ Found existing Whisper models: {model_files}")
                    # SURGICAL FIX 3: Validate cached models and load with timeout
                    for model_name in ['tiny', 'base', 'small']:  # Start with smallest for faster testing
                        expected_file = f"{model_name}.pt"
                        if expected_file in model_files:
                            model_path = os.path.join(cache_dir, expected_file)
                            file_size = os.path.getsize(model_path)
                            
                            # Check minimum expected sizes to detect corruption
                            min_sizes = {'tiny': 30_000_000, 'base': 140_000_000, 'small': 460_000_000}
                            if file_size < min_sizes.get(model_name, 30_000_000):
                                logger.warning(f"üóëÔ∏è Corrupted cache detected for {model_name}: {file_size} bytes (expected >{min_sizes[model_name]})")
                                os.remove(model_path)
                                continue
                            
                            logger.info(f"üéØ Loading cached Whisper '{model_name}' model ({file_size} bytes)...")

                            # Load with timeout protection and explicit cache dir
                            signal.signal(signal.SIGALRM, cuda_timeout_handler)
                            signal.alarm(45)  # 45 second timeout for model loading
                            try:
                                logger.info(f"üì• Loading from cache: {whisper_cache}")
                                whisper_model = whisper.load_model(model_name, device="cuda", download_root=whisper_cache)
                                logger.info(f"‚úÖ Successfully loaded cached Whisper '{model_name}' model on GPU")
                                signal.alarm(0)
                                return whisper_model
                            except Exception as load_e:
                                signal.alarm(0)
                                logger.warning(f"‚ö†Ô∏è Failed to load cached {model_name}: {load_e}")
                                continue
            else:
                logger.info("üìÅ Creating Whisper cache directory...")
                os.makedirs(cache_dir, exist_ok=True)
            
            # If no cached models found, download directly with timeout
            logger.warning("‚ö†Ô∏è No cached Whisper models found - downloading directly")
            
            def download_whisper_model_direct(model_name):
                """Download Whisper model directly using requests with timeout"""
                import requests
                from tqdm import tqdm
                
                # Whisper model URLs (from the documentation)
                model_urls = {
                    'tiny': 'https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt',
                    'base': 'https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt', 
                    'small': 'https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt'
                }
                
                if model_name not in model_urls:
                    return False, f"Model '{model_name}' not supported"
                
                url = model_urls[model_name]
                model_path = os.path.join(cache_dir, f"{model_name}.pt")
                
                try:
                    logger.info(f"üåê Downloading Whisper '{model_name}' model from: {url}")
                    
                    # Download with progress bar and extended timeout for large models
                    response = requests.get(url, stream=True, timeout=(30, 300))  # 30s connect, 5min read timeout
                    response.raise_for_status()
                    
                    total_size = int(response.headers.get('content-length', 0))
                    logger.info(f"üì¶ Model size: {total_size / 1024 / 1024:.1f} MB")
                    
                    with open(model_path, 'wb') as f:
                        if total_size == 0:
                            f.write(response.content)
                        else:
                            downloaded = 0
                            for chunk in response.iter_content(chunk_size=8192):
                                if chunk:
                                    f.write(chunk)
                                    downloaded += len(chunk)
                                    # Log progress every 10MB
                                    if downloaded % (10 * 1024 * 1024) < 8192:
                                        progress = (downloaded / total_size) * 100
                                        logger.info(f"üì• Download progress: {progress:.1f}% ({downloaded / 1024 / 1024:.1f}MB)")
                    
                    logger.info(f"‚úÖ Successfully downloaded Whisper '{model_name}' model")
                    return True, None
                    
                except requests.exceptions.Timeout:
                    logger.error(f"‚è∞ Download timeout for '{model_name}' model")
                    return False, "timeout"
                except Exception as e:
                    logger.error(f"‚ùå Download failed for '{model_name}': {e}")
                    return False, str(e)
            
            # SURGICAL FIX 4: Start with tiny model for fastest download, force GPU loading
            logger.info("üéØ Starting with tiny model for fastest initialization")
            
            for model_name in ['tiny', 'base', 'small']:
                logger.info(f"üì• Attempting to download {model_name} model...")
                success, error = download_whisper_model_direct(model_name)
                
                if success:
                    logger.info(f"‚úÖ Downloaded {model_name} model, now loading with GPU...")
                    
                    # Load with timeout and force GPU
                    signal.signal(signal.SIGALRM, cuda_timeout_handler)
                    signal.alarm(60)  # 60 second timeout for fresh model loading
                    try:
                        whisper_model = whisper.load_model(model_name, device="cuda")
                        logger.info(f"‚úÖ Successfully loaded Whisper '{model_name}' model on GPU")
                        signal.alarm(0)
                        break
                    except Exception as load_e:
                        signal.alarm(0)
                        logger.error(f"‚ùå Failed to load downloaded {model_name}: {load_e}")
                        # Remove corrupted download
                        try:
                            corrupted_path = os.path.join(cache_dir, f"{model_name}.pt")
                            if os.path.exists(corrupted_path):
                                os.remove(corrupted_path)
                                logger.info(f"üóëÔ∏è Removed corrupted {model_name} model")
                        except:
                            pass
                        continue
                else:
                    logger.warning(f"{model_name} model download failed: {error}")
                    if model_name == 'small':  # Last attempt
                        logger.error(f"‚ùå All Whisper model downloads failed: {error}")
                        return None
            
            logger.info("‚úÖ Whisper model loaded successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load Whisper model: {e}")
            import traceback
            logger.error(f"‚ùå Full traceback: {traceback.format_exc()}")
            
            # Try system whisper as fallback
            logger.info("üîÑ Trying system whisper command as fallback...")
            try:
                import subprocess
                result = subprocess.run(['which', 'whisper'], capture_output=True, text=True)
                if result.returncode == 0:
                    logger.info("‚úÖ System whisper found, using as fallback")
                    return "system_whisper"  # Special marker for system whisper
                else:
                    logger.warning("‚ö†Ô∏è System whisper not found")
            except Exception as fallback_e:
                logger.error(f"‚ùå System whisper fallback failed: {fallback_e}")
            
            return None
    return whisper_model

# ‚îÄ‚îÄ‚îÄ Model Unloading Functions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def unload_tts_model():
    """Unload only TTS model to free GPU memory for Whisper"""
    global tts_model
    
    if tts_model is not None:
        logger.info("üóëÔ∏è Unloading TTS model to free GPU memory for Whisper")
        del tts_model
        tts_model = None
        
        # Aggressive GPU cleanup
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()
            torch.cuda.empty_cache()
        
        log_gpu_memory("after TTS unload")

def unload_whisper_model():
    """Unload only Whisper model to free GPU memory for TTS"""
    global whisper_model
    
    if whisper_model is not None:
        logger.info("üóëÔ∏è Unloading Whisper model to free GPU memory for TTS")
        del whisper_model
        whisper_model = None
        
        # Aggressive GPU cleanup
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()
            torch.cuda.empty_cache()
        
        log_gpu_memory("after Whisper unload")

def unload_models():
    """Unload TTS and Whisper models to free GPU memory"""
    global tts_model, whisper_model
    
    log_gpu_memory("before unload")
    
    if tts_model is not None:
        logger.info("üóëÔ∏è Unloading TTS model to free GPU memory")
        del tts_model
        tts_model = None
    
    if whisper_model is not None:
        logger.info("üóëÔ∏è Unloading Whisper model to free GPU memory")
        del whisper_model
        whisper_model = None
    
    # Aggressive GPU cleanup
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        # Force garbage collection
        gc.collect()
        # Clear cache again after GC
        torch.cuda.empty_cache()
        
    log_gpu_memory("after unload")

def unload_all_models():
    """Unload all models including Qwen2VL to free maximum GPU memory"""
    logger.info("üóëÔ∏è Unloading ALL models to free GPU memory for vision processing")
    
    log_gpu_memory("before full unload")
    
    # Unload TTS and Whisper
    unload_models()
    
    # Unload Qwen2VL
    from vison_models.llm_connector import unload_qwen_model
    unload_qwen_model()
    
    # Additional aggressive cleanup
    if torch.cuda.is_available():
        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        # Wait a moment for cleanup to complete
        time.sleep(0.5)
        torch.cuda.empty_cache()
    
    log_gpu_memory("after full unload")
    logger.info("üßπ All models unloaded - maximum GPU memory available")

def reload_models_if_needed():
    """Reload models if they were unloaded"""
    global tts_model, whisper_model
    
    if tts_model is None:
        logger.info("üîÑ Reloading TTS model")
        load_tts_model()
    
    if whisper_model is None:
        logger.info("üîÑ Reloading Whisper model")
        load_whisper_model()

# ‚îÄ‚îÄ‚îÄ TTS Generation Function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def generate_speech(text, model=None, audio_prompt=None, exaggeration=0.5, temperature=0.8, cfg_weight=0.5):
    """Generate speech using TTS model"""
    from chatterbox.tts import punc_norm

    if model is None:
        model = load_tts_model()
    
    if model is None:
        raise RuntimeError("TTS Model could not be loaded (returned None)")

    try:
        logger.info(f"üéôÔ∏è Generating speech for text (length: {len(text)} chars)")
        normalized = punc_norm(text)
        logger.info(f"üìù Normalized text: {normalized[:100]}...")
        if torch.cuda.is_available():
            try:
                logger.info(f"üîä Starting TTS generation on CUDA (exaggeration={exaggeration}, temp={temperature})")
                wav = model.generate(
                    normalized,
                    audio_prompt_path=audio_prompt,
                    exaggeration=exaggeration,
                    temperature=temperature,
                    cfg_weight=cfg_weight
                )
                logger.info(f"‚úÖ TTS generation completed, audio shape: {wav.shape}")
            except RuntimeError as e:
                if "CUDA" in str(e) or "no kernel image" in str(e):
                    logger.error(f"CUDA Error: {e}")
                    logger.warning("‚ö†Ô∏è CUDA ARCHITECTURE ERROR DETECTED (RTX 50-series?)")
                    logger.warning("Falling back to CPU-only mode for Chatterbox via FULL RELOAD.")
                    
                    # Mark CUDA as broken globally so we don't retry it
                    global _cuda_is_broken
                    _cuda_is_broken = True
                    
                    # Unload the broken GPU model
                    torch.cuda.empty_cache()
                    unload_tts_model()
                    
                    try:
                        # Reload model specifically on CPU
                        # load_tts_model will see _cuda_is_broken and use CPU
                        model = load_tts_model(force_cpu=True)
                        
                        logger.info("üîÑ Model reloaded on CPU. Retrying generation...")
                        wav = model.generate(
                            normalized,
                            audio_prompt_path=audio_prompt,
                            exaggeration=exaggeration,
                            temperature=temperature,
                            cfg_weight=cfg_weight,
                            device="cpu"
                        )
                        logger.info("‚úÖ Chatterbox CPU fallback generation successful")
                    except Exception as e2:
                        logger.error(f"CPU Fallback and Reload Failed: {e2}")
                        raise ValueError("Generation failed on both GPU and CPU") from e2
                else:
                    raise
        else:
            wav = model.generate(
                normalized,
                audio_prompt_path=audio_prompt,
                exaggeration=exaggeration,
                temperature=temperature,
                cfg_weight=cfg_weight,
                device="cpu"
            )
        return (model.sr, wav.squeeze(0).numpy())
    except Exception as e:
        logger.error(f"TTS Error: {e}")
        raise

# ‚îÄ‚îÄ‚îÄ VRAM-Optimized Sequential Model Functions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def diagnose_whisper_issues():
    """Quick diagnostic to identify Whisper loading issues"""
    logger.info("üîç WHISPER DIAGNOSTIC START")
    
    # Test 1: Check network connectivity
    try:
        import requests
        response = requests.get("https://openaipublic.azureedge.net", timeout=10)
        logger.info(f"‚úÖ Network OK: {response.status_code}")
    except Exception as e:
        logger.error(f"‚ùå Network issue: {e}")
    
    # Test 2: Check cache directory
    import os
    cache_dir = os.path.expanduser("~/.cache/whisper")
    if os.path.exists(cache_dir):
        files = os.listdir(cache_dir)
        logger.info(f"üìÅ Cache files: {files}")
        # Check for corrupted files
        for f in files:
            if f.endswith('.pt'):
                size = os.path.getsize(os.path.join(cache_dir, f))
                logger.info(f"üì¶ {f}: {size} bytes")
    else:
        logger.info("üìÅ No cache directory found")
    
    # Test 3: Check CUDA availability
    try:
        import torch
        logger.info(f"üîß CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            logger.info(f"üîß CUDA devices: {torch.cuda.device_count()}")
            logger.info(f"üîß Current device: {torch.cuda.current_device()}")
    except Exception as e:
        logger.error(f"‚ùå CUDA check failed: {e}")
    
    logger.info("üîç WHISPER DIAGNOSTIC END")

def use_whisper_model_optimized():
    """Load Whisper model with VRAM optimization and surgical fixes"""
    global whisper_model, tts_model
    
    logger.info("üîÑ Starting VRAM-optimized Whisper loading")
    log_gpu_memory("before Whisper optimization")
    
    # Run diagnostics first
    diagnose_whisper_issues()
    
    # Unload TTS model to free VRAM for Whisper
    unload_tts_model()
    
    # Load Whisper model with timeout and fallbacks
    if whisper_model is None:
        load_whisper_model()
    
    log_gpu_memory("after Whisper loaded")
    return whisper_model

def use_tts_model_optimized():
    """Load TTS model with VRAM optimization (unload Whisper first)"""
    global tts_model, whisper_model
    
    logger.info("üîÑ Starting VRAM-optimized TTS loading")
    log_gpu_memory("before TTS optimization")
    
    # Unload Whisper model to free VRAM for TTS
    unload_whisper_model()
    
    # Load TTS model
    if tts_model is None:
        load_tts_model()
    
    log_gpu_memory("after TTS loaded")
    return tts_model

def transcribe_with_whisper_optimized(audio_path, auto_unload=True):
    """Transcribe audio with VRAM optimization and optional auto-unload"""
    logger.info(f"üé§ Starting VRAM-optimized transcription for: {audio_path}")

    # Load Whisper with optimization
    whisper_model = use_whisper_model_optimized()

    if whisper_model is None:
        raise RuntimeError("Failed to load Whisper model")

    try:
        # Check if using system whisper fallback
        if whisper_model == "system_whisper":
            logger.info("üîß Using system whisper command for transcription")
            import subprocess
            import json
            import tempfile

            # Use system whisper command with JSON output
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_json:
                # Use system temp directory instead of hardcoded /tmp for security
                temp_dir = tempfile.gettempdir()
                cmd = ['whisper', audio_path, '--output_format', 'json', '--output_dir', temp_dir, '--model', 'tiny']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)

                if result.returncode == 0:
                    # Parse the output JSON file
                    base_name = os.path.splitext(os.path.basename(audio_path))[0]
                    json_file = os.path.join(temp_dir, f"{base_name}.json")

                    try:
                        with open(json_file, 'r') as f:
                            json_result = json.load(f)
                        os.unlink(json_file)  # Cleanup
                        logger.info(f"‚úÖ System whisper transcription completed: {json_result.get('text', '')[:100]}...")
                        return json_result
                    except Exception as parse_e:
                        logger.error(f"‚ùå Failed to parse system whisper JSON: {parse_e}")
                        # Fallback to stdout parsing
                        if result.stdout:
                            return {"text": result.stdout.strip()}
                        else:
                            raise RuntimeError(f"System whisper failed: {result.stderr}")
                else:
                    raise RuntimeError(f"System whisper command failed: {result.stderr}")
        else:
            # Use Python whisper library
            logger.info(f"üé§ Starting Whisper transcription for: {audio_path}")
            logger.info(f"üîß Using model on device: {whisper_model.device}")

            result = whisper_model.transcribe(
                audio_path,
                fp16=False,
                language='en',
                task='transcribe',
                verbose=True
            )

            logger.info(f"‚úÖ Transcription completed: {result.get('text', '')[:100]}...")
            logger.info(f"üìä Transcription segments: {len(result.get('segments', []))}")
            return result

    except Exception as e:
        logger.error(f"‚ùå Transcription failed: {e}")
        raise
    finally:
        # Automatically unload Whisper to free VRAM (configurable)
        if whisper_model != "system_whisper" and auto_unload:
            logger.info("üóëÔ∏è Auto-unloading Whisper after transcription")
            unload_whisper_model()
        elif whisper_model != "system_whisper":
            logger.info("‚ÑπÔ∏è Keeping Whisper model loaded (auto_unload=False)")
        # System whisper doesn't need unloading since it's not loaded in Python

def generate_speech_optimized(text, audio_prompt=None, exaggeration=0.5, temperature=0.8, cfg_weight=0.5, auto_unload=True):
    """Generate speech with VRAM optimization and optional auto-unload"""
    logger.info(f"üîä Starting VRAM-optimized TTS generation for: {text[:50]}...")

    # Load TTS with optimization
    tts_model = use_tts_model_optimized()

    if tts_model is None:
        logger.error("‚ùå TTS model is unavailable - cannot generate speech")
        # Return a placeholder response instead of crashing
        return None, None

    try:
        # Generate speech
        result = generate_speech(text, tts_model, audio_prompt, exaggeration, temperature, cfg_weight)

        logger.info("‚úÖ TTS generation completed")
        return result

    except Exception as e:
        logger.error(f"‚ùå TTS generation failed: {e}")
        raise
    finally:
        # Automatically unload TTS to free VRAM (configurable)
        if auto_unload:
            logger.info("üóëÔ∏è Auto-unloading TTS after generation")
            unload_tts_model()
        else:
            logger.info("‚ÑπÔ∏è Keeping TTS model loaded (auto_unload=False)")

# ‚îÄ‚îÄ‚îÄ Model Access Functions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def get_tts_model():
    """Get TTS model, loading if necessary"""
    global tts_model
    if tts_model is None:
        load_tts_model()
    return tts_model

def get_whisper_model():
    """Get Whisper model, loading if necessary"""
    global whisper_model
    if whisper_model is None:
        load_whisper_model()
    return whisper_model

# ‚îÄ‚îÄ‚îÄ Smart Generation Function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def generate_speech_smart(
    text: str,
    mode: str = "auto",
    voice_model: Optional[str] = None,
    audio_prompt: Optional[str] = None,
    **kwargs
):
    """
    Smart speech generation that picks the right engine
    
    Args:
        text: Text to speak
        mode: "interactive", "podcast", "lightweight", or "auto"
        voice_model: RVC model name (for podcast mode)
        audio_prompt: Audio file for cloning (for interactive mode)
    
    Returns:
        (sample_rate, audio_array)
    """
    if mode == "auto":
        # Auto-detect based on context
        if voice_model:
            mode = "podcast"
        elif audio_prompt:
            mode = "interactive"
        else:
            mode = "interactive"  # Default to Chatterbox
    
    mode_map = {
        "interactive": TTSMode.INTERACTIVE,
        "podcast": TTSMode.PODCAST,
        "lightweight": TTSMode.LIGHTWEIGHT
    }
    
    target_mode = mode_map.get(mode, TTSMode.INTERACTIVE)
    
    if target_mode == TTSMode.INTERACTIVE:
        return generate_speech_optimized(text, audio_prompt=audio_prompt, **kwargs)
        
    return tts_generate_speech(
        text,
        mode=target_mode,
        voice_model=voice_model,
        audio_prompt=audio_prompt,
        **kwargs
    )

