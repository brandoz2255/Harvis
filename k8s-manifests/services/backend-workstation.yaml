# Backend Workstation Deployment - Dedicated ML Node
# Runs on Node 2 (pop-os-343570d8) with RTX 3090 Ti for ML workloads
# NO Ollama here - calls Ollama on Node 1 over network
#
# Workloads:
#   - Whisper STT (speech-to-text)
#   - Chatterbox TTS (text-to-speech)
#   - Voice cloning
#   - Embedding generation
#
# GPU Usage: Full 24GB VRAM dedicated to ML (no LLM competition)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: harvis-ai-backend-workstation
  namespace: ai-agents
  labels:
    app.kubernetes.io/name: harvis-ai
    app.kubernetes.io/component: backend
    app.kubernetes.io/variant: workstation
    gpu-role: dedicated-ml
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: harvis-ai
      app.kubernetes.io/component: backend
      app.kubernetes.io/variant: workstation
  template:
    metadata:
      labels:
        app.kubernetes.io/name: harvis-ai
        app.kubernetes.io/component: backend
        app.kubernetes.io/variant: workstation
        gpu-role: dedicated-ml
    spec:
      runtimeClassName: nvidia
      # Node 2: pop-os-343570d8 with RTX 3090 Ti (24GB VRAM) for ML
      nodeSelector:
        kubernetes.io/hostname: pop-os-343570d8

      initContainers:
        # Pre-download TTS and Whisper models
        - name: download-models
          image: "dulc3/jarvis-backend:v2.12"
          imagePullPolicy: Always
          command: ["/app/entrypoint.sh", "download-models"]
          env:
            - name: HF_HOME
              value: "/models-cache/huggingface"
            - name: TRANSFORMERS_CACHE
              value: "/models-cache/huggingface"
            - name: WHISPER_CACHE
              value: "/models-cache/whisper"
          volumeMounts:
            - name: ml-models-cache
              mountPath: /models-cache
          resources:
            requests:
              memory: 4Gi
              cpu: 1000m
            limits:
              memory: 8Gi
              cpu: 4000m

      containers:
        - name: harvis-backend
          image: "dulc3/jarvis-backend:v2.12"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: harvis-ai-backend-secret
                  key: database-url
            - name: OLLAMA_API_KEY
              valueFrom:
                secretKeyRef:
                  name: harvis-ai-backend-secret
                  key: ollama-api-key
            # Call Ollama on Node 1 over Kubernetes network
            - name: OLLAMA_URL
              value: "http://harvis-ai-ollama-workstation:11434"
            - name: BACKEND_URL
              value: "http://harvis-ai-backend-workstation-svc:8000"
            # Model cache configuration
            - name: HF_HOME
              value: "/models-cache/huggingface"
            - name: TRANSFORMERS_CACHE
              value: "/models-cache/huggingface"
            - name: WHISPER_CACHE
              value: "/models-cache/whisper"
            # Full GPU for ML workloads
            - name: CUDA_VISIBLE_DEVICES
              value: "0"
            # Production uvicorn settings
            - name: UVICORN_WORKERS
              value: "2"
            - name: UVICORN_TIMEOUT_KEEP_ALIVE
              value: "120"
          envFrom:
            - configMapRef:
                name: harvis-ai-backend-workstation-config
            - secretRef:
                name: harvis-ai-backend-secret
          resources:
            requests:
              memory: 16Gi
              cpu: 4000m
            limits:
              nvidia.com/gpu: 1  # Full RTX 3090 Ti for ML
              memory: 48Gi
              cpu: 16000m
          volumeMounts:
            - name: embedding
              mountPath: /app/embedding
            - name: tmp
              mountPath: /tmp
            - name: ml-models-cache
              mountPath: /models-cache
          command: ["uvicorn"]
          args:
            - "main:app"
            - "--host"
            - "0.0.0.0"
            - "--port"
            - "8000"
            - "--timeout-keep-alive"
            - "120"
            - "--log-level"
            - "info"
          livenessProbe:
            httpGet:
              path: /docs
              port: http
            initialDelaySeconds: 90
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /docs
              port: http
            initialDelaySeconds: 60
            periodSeconds: 10

      volumes:
        # Embeddings - local ephemeral storage (regenerable)
        - name: embedding
          emptyDir:
            sizeLimit: 10Gi
        # ML models cache - init container downloads models at startup
        # Models stay in GPU memory after loading, no need for persistent storage
        - name: ml-models-cache
          emptyDir:
            sizeLimit: 50Gi
        - name: tmp
          persistentVolumeClaim:
            claimName: harvis-audio-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: harvis-ai-backend-workstation-svc
  namespace: ai-agents
  labels:
    app.kubernetes.io/name: harvis-ai
    app.kubernetes.io/component: backend
    app.kubernetes.io/variant: workstation
spec:
  type: ClusterIP
  ports:
    - name: backend
      port: 8000
      targetPort: http
      protocol: TCP
  selector:
    app.kubernetes.io/name: harvis-ai
    app.kubernetes.io/component: backend
    app.kubernetes.io/variant: workstation
