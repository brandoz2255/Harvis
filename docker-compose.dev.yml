# Docker Compose for Development Environment
# Usage: docker-compose -f docker-compose.dev.yml up
#
# Features:
# - Hot-reload enabled for frontend and backend
# - Pulls images from localhost:5000 or builds locally
# - Same network as services (PostgreSQL, n8n, Ollama)
# - No GPU constraints for easier dev environment

services:
  # Nginx reverse proxy
  nginx:
    image: nginx:alpine
    container_name: harvis-nginx-dev
    restart: unless-stopped
    ports:
      - "9000:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    networks:
      - ollama-n8n-network
    depends_on:
      - backend
      - frontend

  # Backend service (Python FastAPI)
  backend:
    # Option 1: Pull from local registry (if image exists)
    image: localhost:5000/jarvis-backend:dev-latest

    # Option 2: Build locally (uncomment to build instead of pull)
    # build:
    #   context: ./python_back_end
    #   dockerfile: Dockerfile

    container_name: harvis-backend-dev
    restart: unless-stopped

    # Development mode: Enable hot-reload
    volumes:
      - ./python_back_end:/app
      - ./embedding:/app/embedding
      - /tmp:/tmp
      - /var/run/docker.sock:/var/run/docker.sock
      # Mount model cache for faster startup
      - backend-models-cache:/models-cache
      # Artifact storage for generated documents
      - artifact_data:/data/artifacts

    ports:
      - "8000:8000"

    env_file:
      - ./python_back_end/.env

    environment:
      # Development-specific environment variables
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=DEBUG
      - UVICORN_RELOAD=true

      # Service URLs (same as production)
      - OLLAMA_URL=http://ollama:11434
      - BACKEND_URL=http://backend:8000
      - DATABASE_URL=postgresql://pguser:pgpassword@pgsql:5432/database

      # Model cache paths
      - HF_HOME=/models-cache/huggingface
      - TRANSFORMERS_CACHE=/models-cache/huggingface
      - WHISPER_CACHE=/models-cache/whisper

      # Artifact storage for generated documents
      - ARTIFACT_STORAGE_DIR=/data/artifacts

    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload --log-level debug

    networks:
      - ollama-n8n-network

    depends_on:
      - pgsql
      - ollama

  # Frontend service (Next.js)
  frontend:
    # Option 1: Pull from local registry (if image exists)
    image: localhost:5000/jarvis-frontend:dev-latest

    # Option 2: Build locally (uncomment to build instead of pull)
    # build:
    #   context: ./front_end/jfrontend
    #   dockerfile: Dockerfile

    container_name: harvis-frontend-dev
    restart: unless-stopped

    # Development mode: Mount source for hot-reload
    volumes:
      - ./front_end/jfrontend:/app
      - /app/node_modules  # Prevent overwriting node_modules
      - /app/.next         # Cache Next.js build

    ports:
      - "3000:3000"

    env_file:
      - ./front_end/jfrontend/.env.local

    environment:
      # Development mode
      - NODE_ENV=development
      - NEXT_TELEMETRY_DISABLED=1

      # Backend URL for API calls
      - NEXT_PUBLIC_BACKEND_URL=http://localhost:9000
      - DATABASE_URL=postgresql://pguser:pgpassword@pgsql:5432/database

    command: npm run dev

    networks:
      - ollama-n8n-network

    depends_on:
      - backend
      - pgsql

  # PostgreSQL database (shared with all environments)
  pgsql:
    image: pgvector/pgvector:pg15
    container_name: pgsql-db-dev
    restart: unless-stopped
    environment:
      POSTGRES_USER: pguser
      POSTGRES_PASSWORD: pgpassword
      POSTGRES_DB: database
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=C"
    volumes:
      - pgsql_data_dev:/var/lib/postgresql/data
      - ./init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    ports:
      - "5432:5432"
    networks:
      - ollama-n8n-network

  # Ollama service (local LLM server)
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-dev
    restart: unless-stopped

    # Optional: Enable GPU for Ollama in dev (uncomment if needed)
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    #   - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    volumes:
      - ollama_data_dev:/root/.ollama

    ports:
      - "11434:11434"

    networks:
      - ollama-n8n-network

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3

  # n8n workflow automation (optional for dev)
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n-dev
    restart: unless-stopped
    ports:
      - "5678:5678"
    volumes:
      - n8n_data_dev:/home/node/.n8n
    environment:
      N8N_BASIC_AUTH_ACTIVE: "true"
      N8N_BASIC_AUTH_USER: "admin"
      N8N_BASIC_AUTH_PASSWORD: "adminpass"
      N8N_PERSONAL_API_KEY: "${N8N_PERSONAL_API_KEY}"
      DB_TYPE: "postgres"
      DB_POSTGRES_HOST: "pgsql-db-dev"
      DB_POSTGRES_PORT: "5432"
      DB_POSTGRES_DATABASE: "database"
      DB_POSTGRES_USER: "pguser"
      DB_POSTGRES_PASSWORD: "pgpassword"
    networks:
      - ollama-n8n-network
    depends_on:
      - pgsql

networks:
  ollama-n8n-network:
    external: true

volumes:
  pgsql_data_dev:
    driver: local
  ollama_data_dev:
    driver: local
  n8n_data_dev:
    driver: local
  backend-models-cache:
    driver: local
